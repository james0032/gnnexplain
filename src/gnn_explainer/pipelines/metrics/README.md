# Metrics Pipeline - Explanation Analysis Tools

This directory contains tools for analyzing and understanding GNN explanation outputs.

## Scripts

### inspect_explanations.py

A comprehensive script for inspecting and analyzing pickle files generated by the GNN explainer pipeline.

**Features:**
- Automatically detects and loads both `torch.save` and `pickle.dump` files
- Handles CUDA tensors gracefully (maps to CPU)
- Recursively analyzes nested data structures
- Displays shape, dtype, and statistics for tensors and arrays
- Pretty-prints the structure in a tree format

**Usage:**

```bash
# Inspect all pickle files in the default explanations directory
python src/gnn_explainer/pipelines/metrics/inspect_explanations.py

# Inspect pickle files in a custom directory
python src/gnn_explainer/pipelines/metrics/inspect_explanations.py /path/to/directory
```

**Example Output:**

```
Found 3 pickle file(s)

================================================================================
Inspecting: page_explanations.pkl
================================================================================
File size: 75.01 MB

Top-level type: dict

Structure:
├─ page_explanations
  type: dict
  keys: 8
  key names: ['explainer_type', 'explanations', 'num_explanations', 'params', ...]
    ├─ page_explanations.explainer_type
      type: str
      value: ImprovedPAGE
    ├─ page_explanations.explanations
      type: list
      length: 10
      sample element:
        ├─ page_explanations.explanations[0]
          type: dict
          keys: 8
          key names: ['triple', 'edge_importance_matrix', 'important_edges', ...]
```

## Explanation File Formats

### gnn_explanations.pkl

**Structure:**
- `explainer_type`: "GNNExplainer"
- `explanations`: List of explanation dicts (one per triple)
  - `triple`: Triple information (head, tail, relation)
  - `explanation`: PyG Explanation object
  - `edge_mask`: Tensor of edge importance scores
  - `important_edges`: Top-K important edges
  - `important_edge_types`: Relation types for important edges
  - `importance_scores`: Scores for important edges
  - `subgraph_size`: Number of nodes/edges in subgraph
- `num_explanations`: Total count
- `params`: Explainer parameters

**File Size:** ~21 MB

### page_explanations.pkl

**Structure:**
- `explainer_type`: "ImprovedPAGE"
- `explanations`: List of explanation dicts
  - `triple`: Triple information
  - `edge_importance_matrix`: Full NxN importance matrix
  - `important_edges`: Top-K edges [2, K]
  - `important_edge_types`: Relation types [K]
  - `importance_scores`: Edge scores [K]
  - `subgraph_info`: Subgraph metadata
  - `latent_representation`: VGAE latent embeddings [N, latent_dim]
  - `prediction_score`: Model prediction score
- `num_explanations`: Total count
- `params`: PAGE explainer parameters
- `subgraph_info`: List of subgraph metadata
- `model_aware`: Whether using model predictions
- `uses_encoder`: Whether using encoder
- `uses_decoder`: Whether using decoder

**File Size:** ~75 MB

### selected_triples.pkl

**Structure:**
- `selected_indices`: Indices in test set [N]
- `selected_edge_index`: Edge indices [2, N]
- `selected_edge_type`: Relation types [N]
- `triples_readable`: List of readable triple dicts
  - `head_idx`, `tail_idx`, `relation_idx`: Indices
  - `head_name`, `tail_name`, `relation_name`: Human-readable names
  - `triple`: String representation
- `num_selected`: Count of selected triples
- `from_test_set`: Boolean flag

**File Size:** ~0.01 MB

## Common Analysis Tasks

### Count Explanations

```python
import pickle

with open("data/05_model_explanations/page_explanations.pkl", "rb") as f:
    data = pickle.load(f)

print(f"Number of explanations: {data['num_explanations']}")
print(f"Explainer type: {data['explainer_type']}")
```

### Access Important Edges

```python
import pickle
import torch

with open("data/05_model_explanations/page_explanations.pkl", "rb") as f:
    data = pickle.load(f)

# Get first explanation
exp = data['explanations'][0]

print(f"Triple: {exp['triple']['triple']}")
print(f"Important edges shape: {exp['important_edges'].shape}")
print(f"Top edge indices: {exp['important_edges'][:, :5]}")
print(f"Top scores: {exp['importance_scores'][:5]}")
```

### Compare Explainers

```python
import pickle

# Load explanations from different explainers
with open("data/05_model_explanations/gnn_explanations.pkl", "rb") as f:
    gnn_data = pickle.load(f)

with open("data/05_model_explanations/page_explanations.pkl", "rb") as f:
    page_data = pickle.load(f)

# Compare first triple
gnn_exp = gnn_data['explanations'][0]
page_exp = page_data['explanations'][0]

print("GNN important edges:", gnn_exp['important_edges'].shape)
print("PAGE important edges:", page_exp['important_edges'].shape)
```

## Notes

- All pickle files use CPU tensors after loading (automatic CUDA→CPU mapping)
- The `inspect_explanations.py` script is read-only and safe to run
- Pickle files should be generated by running: `kedro run --pipeline=explanation`
