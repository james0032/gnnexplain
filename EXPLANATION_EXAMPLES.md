# Explanation Examples: CCDD GNN-DistMult Perturbation Analysis

This document showcases three example explanations generated by the perturbation-based explainer on the CCDD (Chemical Compound - Disease - Disease) dataset using the RGCN-DistMult model.

---

## ðŸŽ¯ Understanding the Visualizations

### Node Colors

| Color | Node Type | Description |
|-------|-----------|-------------|
| **Red (#FF6B6B)** | **Head Entity** | The source/subject node in the triple being explained. In drug-disease predictions, this is typically the **drug/chemical compound** being evaluated. |
| **Pink (#FF9999)** | **Tail Entity** | The target/object node in the triple being explained. In drug-disease predictions, this is typically the **disease** that the drug might treat. |
| **Green (#95E1D3)** | **Context Nodes** | Surrounding entities in the k-hop neighborhood that provide contextual information for the prediction. These nodes help the model understand the relationship between head and tail. |

### Edge Colors (Heatmap)

The edges are colored using a **Yellow â†’ Orange â†’ Red** gradient representing **importance scores**:
- ðŸŸ¡ **Yellow (low importance)**: Edge has minimal impact on the prediction
- ðŸŸ  **Orange (medium importance)**: Edge contributes moderately to the prediction
- ðŸ”´ **Red (high importance)**: Edge is critical for the model's prediction

**Edge width** also indicates importance - thicker edges are more important.

### How to Interpret

The visualization shows:
1. **Head Entity (Red)**: The drug/compound being evaluated
2. **Tail Entity (Pink)**: The disease it might treat
3. **Important Edges (Red/Orange)**: Key relationships the model uses to predict this link
4. **Context Nodes (Green)**: Intermediate entities that connect head to tail
5. **Colorbar**: Quantifies edge importance from 0 (not important) to 1 (critical)

The model's prediction is based on the **subgraph structure** and **relation types** connecting the head and tail entities. Edges with high importance scores (red/orange) are the most influential in the model's decision.

---

## ðŸ“Š Example 1

![Explanation 1](figures/CCDD_GNNDistMult_perturb/explanation_1.png)

### Description

This explanation shows a **chemical compound** (red node, head entity) and its potential relationship to a **disease** (pink node, tail entity).

**Key Observations:**
- The head entity (red) represents the chemical compound being evaluated
- The tail entity (pink) represents the target disease
- Multiple intermediate nodes (green) form the context neighborhood
- Edge colors reveal which relationships are most important for this prediction
- The colorbar on the right quantifies edge importance (0.0 to 1.0 scale)

**Interpretation:**
- Red/orange edges indicate the most critical pathways the model considers
- The subgraph structure shows how the compound connects to the disease through intermediate entities
- Higher importance edges (warmer colors) contributed more to the model's prediction score

---

## ðŸ“Š Example 2

![Explanation 2](figures/CCDD_GNNDistMult_perturb/explanation_13.png)

### Description

This example demonstrates another **compound-disease** link prediction with a different network topology.

**Key Observations:**
- Head entity (red): Source chemical compound
- Tail entity (pink): Target disease
- The neighborhood structure differs from Example 1, showing dataset diversity
- Edge importance distribution varies, indicating different reasoning patterns
- Some edges show very high importance (dark red), while others are less critical

**Interpretation:**
- The model relies on different subgraph patterns for different predictions
- Edge importance reveals which relationships are essential vs. supplementary
- The visualization helps identify the key "reasoning paths" the model uses

---

## ðŸ“Š Example 3

![Explanation 3](figures/CCDD_GNNDistMult_perturb/explanation_18.png)

### Description

The third example showcases yet another prediction pattern with its own unique subgraph structure.

**Key Observations:**
- Red node (head): The chemical compound being evaluated
- Pink node (tail): The disease target
- Context nodes (green) provide neighborhood information
- Edge importance (heatmap) shows which connections matter most
- The subgraph may be denser or sparser depending on the entity's connectivity

**Interpretation:**
- Different triples have different explanation patterns
- The perturbation-based explainer identifies critical edges by measuring prediction change
- These visualizations help validate model predictions and identify potential issues

---

## ðŸ”¬ Technical Details

### Generation Method

These explanations were generated using the **perturbation-based explainer**:

1. **Extract k-hop subgraph** (k=2) around the (head, tail) pair
2. **Get original prediction score** from the full model
3. **Iteratively remove each edge** in the subgraph
4. **Re-score the prediction** without that edge
5. **Compute importance** = |original_score - new_score|
6. **Normalize scores** to [0, 1] range
7. **Visualize** top-K most important edges with heatmap

### Model Architecture

- **Encoder**: RGCN (Relational Graph Convolutional Network)
  - 2 layers
  - Relation-specific message passing
  - 128-dimensional embeddings

- **Decoder**: DistMult
  - Bilinear scoring function
  - score = Î£(h âŠ™ r âŠ™ t)

### Dataset

- **CCDD**: Chemical Compound - Disease - Disease
- **Entities**: Drugs/chemicals and diseases
- **Relations**: Treats, causes, associated_with, etc.
- **Task**: Predict potential drug-disease treatment relationships

---

## ðŸ“– Legend Summary

### Nodes

| Element | Color | Meaning |
|---------|-------|---------|
| **Head Entity** | **ðŸ”´ Red (#FF6B6B)** | Source node - typically a drug/chemical compound in drug-disease predictions |
| **Tail Entity** | **ðŸ©· Pink (#FF9999)** | Target node - typically a disease that the drug might treat |
| **Context Nodes** | **ðŸŸ¢ Green (#95E1D3)** | Neighborhood entities providing contextual information |

### Edges

| Color | Importance | Meaning |
|-------|------------|---------|
| ðŸŸ¡ **Yellow** | Low (0.0-0.3) | Minimal contribution to prediction |
| ðŸŸ  **Orange** | Medium (0.3-0.7) | Moderate contribution to prediction |
| ðŸ”´ **Red** | High (0.7-1.0) | Critical for prediction - removing this edge significantly changes the score |

### Other Elements

| Element | Description |
|---------|-------------|
| **Edge Width** | Thicker = more important |
| **Edge Labels** | Relation types (e.g., "treats", "causes") |
| **Node Labels** | Entity names (truncated if too long) |
| **Colorbar** | Quantifies edge importance from 0 (not important) to 1 (critical) |
| **Title** | Shows the specific triple being explained |

---

## ðŸ’¡ Use Cases

These explanations are valuable for:

1. **Model Debugging**: Verify the model is using reasonable reasoning patterns
2. **Scientific Discovery**: Identify potential novel drug-disease relationships
3. **Trustworthiness**: Understand why the model makes specific predictions
4. **Knowledge Validation**: Check if model reasoning aligns with biological knowledge
5. **Hypothesis Generation**: Find interesting intermediate pathways for further research

---

## ðŸ”— Related Files

- **Explainer Implementation**: [explainers.py](src/explainers.py)
- **Visualization Code**: [visualize_explanation.py](src/visualize_explanation.py)
- **Model Architecture**: [cl_model.py](src/cl_model.py)
- **Evaluation Script**: [cl_eval.py](src/cl_eval.py)

---

**Dataset**: CCDD (Chemical Compound - Disease - Disease)
**Model**: RGCN-DistMult
**Explainer**: Perturbation-based (GPU-accelerated)
**Generated**: October 2024
