# =============================================================================
# GNN Explainer Pipeline Parameters
# =============================================================================

# Data paths (relative to project root)
data:
  train_file: "data/01_raw/robo_train.txt"
  val_file: "data/01_raw/robo_val.txt"
  test_file: "data/01_raw/robo_test.txt"
  node_dict: "data/01_raw/node_dict"
  rel_dict: "data/01_raw/rel_dict"

# Model architecture hyperparameters
model:
  # Model selection
  model_type: "compgcn"          # Options: "rgcn", "compgcn"
  decoder_type: "conve"        # Options: "distmult", "complex", "rotate", "conve"

  # Common parameters
  embedding_dim: 32             # Embedding dimension (200 for ComplEx/RotatE/ConvE, 128 for DistMult)
  num_layers: 2                  # Number of GNN layers
  dropout: 0.2                   # Dropout rate

  # RGCN-specific parameters
  num_bases: 30                  # Number of bases (RGCN only)

  # CompGCN-specific parameters
  comp_fn: "sub"                 # Composition function: "sub", "mult", "corr"

  # ConvE-specific parameters (only used when decoder_type="conve")
  conve_input_drop: 0.2          # Input dropout
  conve_hidden_drop: 0.3         # Hidden layer dropout
  conve_feature_drop: 0.2        # Feature dropout
  conve_num_filters: 32          # Number of conv filters
  conve_kernel_size: 3           # Kernel size for convolution

# Training configuration
training:
  learning_rate: 0.001
  batch_size: 32
  num_epochs: 5
  patience: 10
  weight_decay: 0.0
  gradient_clip: 1.0

# Evaluation settings
evaluation:
  num_neg_samples: 10
  hit_k_values: [1, 3, 10]
  compute_mrr: true
  compute_hits: true
  batch_size: 1024

# Explanation settings
explanation:
  # Explainer selection - which explainers to run
  # Options: ["gnnexplainer", "pgexplainer", "page"]
  # Set to a list of explainers you want to run, or ["all"] to run all explainers
  enabled_explainers: ["pgexplainer"]  # Run only PGExplainer for testing

  # Triple selection parameters
  triple_selection:
    strategy: "test_triples"              # Options: "random", "test_triples", "from_file", "specific_relations", "specific_nodes"
                                          # - "random": randomly select from training graph edges
                                          # - "test_triples": randomly select from test set triples
                                          # - "from_file": load triples from a file (e.g., top10_test.txt)
                                          # - "specific_relations": select triples with specific relation types
                                          # - "specific_nodes": select triples involving specific nodes
    num_triples: 10                       # Number of triples to explain (ignored for "from_file")
    catalog_name: "top10_test"            # Kedro catalog dataset name (preferred method)
    file_path: "data/07_model_output/top10_test.txt"  # Fallback file path for "from_file" strategy
    target_relations: [0, 1]              # For "specific_relations" strategy
    target_nodes: []                      # For "specific_nodes" strategy

  # GNNExplainer parameters
  gnnexplainer:
    gnn_epochs: 200                       # Optimization epochs for each explanation
    gnn_lr: 0.01                          # Learning rate for mask optimization
    top_k_edges: 10                       # Number of top important edges to extract
    subgraph_method: "paths"               # Options: "khop" (PyG k-hop), "paths" (igraph paths)
    khop_distance: 2                      # For khop method: number of hops
    max_path_length: 3                    # For paths method: maximum path length

  # PGExplainer parameters
  pgexplainer:
    pg_epochs: 30                         # Training epochs for explainer network
    pg_lr: 0.003                          # Learning rate for explainer network
    training_edges: 100                   # Number of edges to train explainer on
    top_k_edges: 10                       # Number of top important edges to extract
    subgraph_method: "paths"              # Options: "khop" (PyG k-hop), "paths" (igraph paths)
    khop_distance: 2                      # For khop method: number of hops
    max_path_length: 3                    # For paths method: maximum path length
    use_full_graph_training: false        # Use full graph for training (slower but comprehensive)
    force_retrain: false                  # Force retraining even if cached explainer exists

  # PAGE parameters (Improved Parametric Generative Explainer)
  # Uses CompGCN embeddings + Prediction-aware training
  page:
    train_epochs: 100                     # Training epochs for VGAE
    lr: 0.003                             # Learning rate
    k_hops: 2                             # Number of hops for subgraph extraction (khop method)
    subgraph_method: "paths"              # Options: "khop" (PyG k-hop), "paths" (igraph paths)
    max_path_length: 3                    # For paths method: maximum path length
    encoder_hidden1: 32                   # Encoder hidden layer 1 dimensions
    encoder_hidden2: 16                   # Encoder hidden layer 2 dimensions (unused in improved version)
    latent_dim: 16                        # Latent space dimensions
    decoder_hidden1: 16                   # Decoder hidden layer 1 dimensions
    decoder_hidden2: 16                   # Decoder hidden layer 2 dimensions (unused in improved version)
    dropout: 0.0                          # Dropout rate
    kl_weight: 0.2                        # Weight for KL divergence loss
    prediction_weight: 1.0                # Weight for prediction-aware training (NEW!)
    top_k_edges: 10                       # Number of top important edges to extract

  # Legacy explanation settings (for old explanation pipeline)
  num_explain: 20
  subject_prefixes: ["CHEBI", "UNII", "PUBCHEM.COMPOUND"]
  object_prefixes: ["MONDO"]
  no_prefix_filter: false
  use_fast_explainer: true
  explanation_khops: 2
  max_edges: 2000
  max_path_length: 3

# Visualization settings
visualization:
  explanation_dir: "data/08_reporting/explanations"
  top_k_edges: 20
  figure_size: [15, 10]
  dpi: 300
  node_size: 3000
  font_size: 8
  edge_font_size: 6

# Device configuration
device: "cuda"  # Options: "cuda", "cpu", "mps" (for Mac M1/M2)

# =============================================================================
# MLflow Experiment Tracking Configuration
# =============================================================================
# Controls whether MLflow experiment tracking is enabled
# Set to true to enable MLflow tracking, false to disable (default)
#
# Usage:
#   - Run without MLflow: kedro run
#   - Run with MLflow: kedro run --params=mlflow.enabled:true
mlflow:
  enabled: false                          # Default: disabled (toggle with --params=mlflow.enabled:true)
  tracking_uri: "mlruns"                  # Local tracking directory or remote server URL
  experiment_name: "gnn-explainer"        # Experiment name for organizing runs
